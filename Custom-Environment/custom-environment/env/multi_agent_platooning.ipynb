{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j34ure_4Q3ol"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from gym import Env\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import pygame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OdGXZkzIPKeX"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, position, speed=1.0):\n",
        "        self.position = position\n",
        "        self.speed = speed\n",
        "\n",
        "    def update_position(self):\n",
        "        self.position += self.speed\n",
        "\n",
        "    def update_speed(self, action):\n",
        "        # 0: slow down, 1: maintain speed, 2: speed up\n",
        "        if action == 0:\n",
        "            self.speed = max(0, self.speed - 0.01)\n",
        "        elif action == 2:\n",
        "            self.speed = min(1.0, self.speed + 0.01)\n",
        "\n",
        "class FollowLeaderEnv(gym.Env):\n",
        "    def __init__(self, num_agents, visualize=False):\n",
        "        super(FollowLeaderEnv, self).__init__()\n",
        "\n",
        "        # Define action space: 0 - slow down, 1 - keep speed, 2 - speed up\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # Observation space: distance to leader, agent speed, leader speed\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(3,), dtype=np.float32)\n",
        "\n",
        "        # Initialize agents\n",
        "        self.agents = [Agent(position=0.0 + i * 50) for i in range(num_agents)]\n",
        "\n",
        "        # Target distance to maintain\n",
        "        self.target_distance = 50.0\n",
        "\n",
        "        # Leader's speed range\n",
        "        self.leader_speed_min = 0.25\n",
        "        self.leader_speed_max = 1.0\n",
        "\n",
        "        if visualize:\n",
        "            self.screen = None\n",
        "            self.clock = None\n",
        "            self.is_pygame_initialized = False\n",
        "            self.init_pygame()\n",
        "\n",
        "    def init_pygame(self):\n",
        "        print(\"Initializing Pygame...\")\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((1000, 300))\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.is_pygame_initialized = True\n",
        "        pygame.font.init()\n",
        "        self.font = pygame.font.Font(None, 36)\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset agents and environment\n",
        "        self.agents = [Agent(position=0.0 + i * 50) for i in range(len(self.agents))]\n",
        "        return self._get_observation(self.agents[0], self.agents[-1])  # Return initial observation for the first agent\n",
        "\n",
        "    def step(self, action, agent_idx):\n",
        "        agent = self.agents[agent_idx]\n",
        "        leader = self.agents[agent_idx+1]\n",
        "\n",
        "        # Update agent speed based on action\n",
        "        agent.update_speed(action)\n",
        "        agent.update_position()\n",
        "\n",
        "        # Calculate distance to leader\n",
        "        distance_to_leader = leader.position - agent.position\n",
        "\n",
        "        # Reward calculation\n",
        "        reward = -abs(distance_to_leader - self.target_distance)\n",
        "        done = False\n",
        "\n",
        "        # Penalty for being too close or too far from the leader\n",
        "        if distance_to_leader < 5 or distance_to_leader > 100:\n",
        "            done = True\n",
        "\n",
        "        if self.agents[-1].position >= 900:\n",
        "            reward += 100 if 40 < distance_to_leader < 60 else 50\n",
        "            done = True\n",
        "\n",
        "        # Observation: distance to leader, agent speed, leader speed\n",
        "        state = np.array([distance_to_leader, agent.speed, leader.speed], dtype=np.float32)\n",
        "\n",
        "        return state, reward, done, {}\n",
        "\n",
        "    def leader_move(self):\n",
        "        leader = self.agents[-1]\n",
        "        leader_action = np.random.choice([0, 1, 2])\n",
        "        leader.update_speed(leader_action)\n",
        "        leader.update_position()\n",
        "\n",
        "    def render(self):\n",
        "        if not self.is_pygame_initialized:\n",
        "            return\n",
        "\n",
        "        self.screen.fill((0, 0, 0))\n",
        "\n",
        "        # Draw end\n",
        "        pygame.draw.circle(self.screen, (255, 0, 0), (900, 150), 10)\n",
        "\n",
        "        # Draw the agents\n",
        "        for agent in self.agents:\n",
        "            pygame.draw.circle(self.screen, (0, 255, 0), (int(agent.position), 150), 10)\n",
        "\n",
        "        # Display leader speed\n",
        "        speed_text = self.font.render(f\"Leader Speed: {round(self.agents[-1].speed, 3)}\", True, (255, 255, 255))\n",
        "        self.screen.blit(speed_text, (10, 10))\n",
        "\n",
        "        pygame.display.flip()\n",
        "        self.clock.tick(60)\n",
        "\n",
        "    def close(self):\n",
        "        if self.is_pygame_initialized:\n",
        "            print(\"Closing Pygame...\")\n",
        "            pygame.quit()\n",
        "            self.is_pygame_initialized = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rsEO-pezVs0a"
      },
      "outputs": [],
      "source": [
        "# Neural network for Q-learning (DQN)\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zuEUWIWGq4mv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Pygame...\n",
            "Closing Pygame...\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Initialize the environment with visualization\n",
        "env = FollowLeaderEnv(num_agents=6, visualize=True)  # Assuming you want 5 agents for the example\n",
        "\n",
        "# Get the state and action dimensions from the environment\n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "# Initialize a new DQN network for testing\n",
        "dqn_test = DQN(state_dim, action_dim)\n",
        "\n",
        "# Load the trained model's weights\n",
        "dqn_test.load_state_dict(torch.load(\"policy_net_weights_final.pth\"))\n",
        "\n",
        "# Set the model to evaluation mode \n",
        "dqn_test.eval()\n",
        "\n",
        "done = False\n",
        "\n",
        "# Loop to run the episode\n",
        "while not done:\n",
        "    # Check for pygame events\n",
        "    for event in pygame.event.get():\n",
        "        if event.type == pygame.KEYDOWN:\n",
        "            keys = pygame.key.get_pressed()\n",
        "            if keys[pygame.K_ESCAPE]:\n",
        "                done = True\n",
        "        if event.type == pygame.QUIT:\n",
        "            done = True\n",
        "\n",
        "    time.sleep(0.05)  # Add a small delay to slow down the visualization (optional)\n",
        "\n",
        "    # Loop over each agent to select actions and update their states\n",
        "    for i in range(len(env.agents) - 1):  # '-1' excludes the leader from the loop\n",
        "        agent = env.agents[i]\n",
        "\n",
        "        # Choose the best action for the agent (exploit, no exploration during testing)\n",
        "        with torch.no_grad():\n",
        "            action = torch.argmax(dqn_test(torch.FloatTensor([env.agents[i+1].position-env.agents[i].position, env.agents[i].speed, env.agents[i+1].speed]))).item()\n",
        "\n",
        "        # Step the environment with the chosen action\n",
        "        next_state, reward, done, _ = env.step(action, i)\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Render the environment to visualize the agent's movements\n",
        "        env.render()\n",
        "\n",
        "    # Update the leader's position independently after all agents move\n",
        "    env.leader_move()\n",
        "\n",
        "    # Render the environment again after leader movement\n",
        "    env.render()\n",
        "\n",
        "# Close the environment\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
