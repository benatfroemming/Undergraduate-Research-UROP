{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j34ure_4Q3ol"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from gym import Env\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Platoon:\n",
    "    def __init__(self, platoon_members):\n",
    "        self.platoon_members = platoon_members\n",
    "\n",
    "    def split_platoon(self, exit_index):\n",
    "        # Handle last agent separating\n",
    "        if exit_index == 0 and len(self.platoon_members) > 1:\n",
    "            front_platoon_members = self.platoon_members[1:]  # Everything except the last agent\n",
    "            exiting_agent = self.platoon_members[0]  # The last agent is the one leaving\n",
    "\n",
    "            # Ensure the exiting agent is marked as the leader\n",
    "            exiting_agent.is_leader = True\n",
    "            new_exiting_platoon = Platoon([exiting_agent])\n",
    "            \n",
    "            # Update the original platoon to be the front platoon\n",
    "            self.platoon_members = front_platoon_members\n",
    "            self.platoon_members[-1].is_leader = True  # Ensure the new front platoon has a leader\n",
    "            return new_exiting_platoon, None\n",
    "\n",
    "        # Handle leader (first agent) separating\n",
    "        elif exit_index == len(self.platoon_members) - 1 and len(self.platoon_members) > 1:\n",
    "            rear_platoon_members = self.platoon_members[:len(self.platoon_members)-1]  # Everything except the leader\n",
    "            exiting_agent = self.platoon_members[-1]  # The leader is the one leaving\n",
    "            new_exiting_platoon = Platoon([exiting_agent])\n",
    "            \n",
    "            # Update the original platoon to be the rear platoon\n",
    "            self.platoon_members = rear_platoon_members\n",
    "            self.platoon_members[-1].is_leader = True  # Ensure the new rear platoon has a leader\n",
    "            return new_exiting_platoon, None\n",
    "\n",
    "        # Handle middle agent separating\n",
    "        elif 0 < exit_index < len(self.platoon_members) - 1:\n",
    "            rear_platoon_members = self.platoon_members[:exit_index]  # Members before the separating agent\n",
    "            exiting_agent = self.platoon_members[exit_index]  # The separating agent\n",
    "            front_platoon_members = self.platoon_members[exit_index + 1:]  # Members after the separating agent\n",
    "\n",
    "            # Set up new platoons for rear and front\n",
    "            exiting_agent.is_leader = True\n",
    "            new_exiting_platoon = Platoon([exiting_agent])\n",
    "            rear_platoon_members[-1].is_leader = True\n",
    "            new_rear_platoon = Platoon(rear_platoon_members)\n",
    "\n",
    "            # Update the original platoon to be the front platoon\n",
    "            self.platoon_members = front_platoon_members\n",
    "            self.platoon_members[-1].is_leader = True\n",
    "\n",
    "            # Return both the exiting agent's new platoon and the rear platoon\n",
    "            return new_exiting_platoon, new_rear_platoon\n",
    "\n",
    "        # If there's only one agent, no split needed; return None\n",
    "        return None, None\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, position, speed, destination, is_leader=False, speed_min=0.25, speed_max=1.2, acceleration=0.005):\n",
    "        self.position = position\n",
    "        self.speed = speed\n",
    "        self.destination = destination\n",
    "        self.is_leader = is_leader\n",
    "        self.done = False\n",
    "        self.velocities = []\n",
    "        self.distances = []\n",
    "        self.direction = 0\n",
    "        \n",
    "        # Leader-specific attributes\n",
    "        self.speed_min = speed_min \n",
    "        self.speed_max = speed_max \n",
    "        self.acceleration = acceleration \n",
    "        self.target_speed = 1.0\n",
    "\n",
    "    def update_position(self):\n",
    "        self.position += self.speed\n",
    "\n",
    "    def update_speed(self, action=None):\n",
    "        if self.is_leader:\n",
    "            if abs(self.speed - self.target_speed) < 0.01:\n",
    "                self.speed = self.target_speed\n",
    "            elif self.speed < self.target_speed:\n",
    "                self.speed = min(self.speed + self.acceleration, self.target_speed)\n",
    "            elif self.speed > self.target_speed:\n",
    "                self.speed = max(self.speed - self.acceleration, self.target_speed)\n",
    "        else:\n",
    "            if action == 0:\n",
    "                self.speed = max(0, self.speed - 0.005)\n",
    "            elif action == 2:\n",
    "                self.speed = min(1.2, self.speed + 0.05)\n",
    "\n",
    "        self.velocities.append(self.speed)\n",
    "\n",
    "class FollowLeaderEnv(gym.Env):\n",
    "    def __init__(self, num_agents, visualize=False):\n",
    "        super(FollowLeaderEnv, self).__init__()\n",
    "        self.num_agents = num_agents\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(3,), dtype=np.float32)\n",
    "\n",
    "        # Initialize agents\n",
    "        initial_position = 50.0\n",
    "        leader_speed = 0.0\n",
    "        \n",
    "        self.agents = [\n",
    "            Agent(position=initial_position + 50 * (i), \n",
    "                  speed=leader_speed, \n",
    "                  destination=1 if i == num_agents - 1 else np.random.randint(2),  \n",
    "                  is_leader=True if i == num_agents - 1 else False)\n",
    "            for i in range(num_agents)\n",
    "        ]\n",
    "\n",
    "        # Initialize platoons with the created agents\n",
    "        self.platoons = [Platoon(self.agents)]\n",
    "        self.dones = {self.platoons[0]: False}\n",
    "\n",
    "        self.target_distance = 50.0\n",
    "        \n",
    "        if visualize:\n",
    "            self.init_pygame()\n",
    "\n",
    "    def init_pygame(self):\n",
    "        print(\"Initializing Pygame...\")\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((1000, 650))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.is_pygame_initialized = True\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 36)\n",
    "\n",
    "    def check_distance_and_request_coupling(self, rear_platoon):\n",
    "        # Loop through each platoon and find others with the same destination\n",
    "        # Initialize variables to track the closest front platoon\n",
    "        closest_platoon = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        # Search for the closest eligible front platoon\n",
    "        for front_platoon in self.platoons:\n",
    "            if front_platoon is rear_platoon:\n",
    "                continue  # Skip self comparison\n",
    "\n",
    "            front_last_agent = front_platoon.platoon_members[0]\n",
    "            front_first_agent = front_platoon.platoon_members[-1]\n",
    "            rear_first_agent = rear_platoon.platoon_members[-1]\n",
    "\n",
    "            # Only check platoons with the same destination and if front is ahead\n",
    "            if rear_first_agent.direction == front_first_agent.direction and \\\n",
    "            front_last_agent.position > rear_first_agent.position:\n",
    "\n",
    "                # Calculate the distance between rear and front platoons\n",
    "                distance = front_last_agent.position - rear_first_agent.position\n",
    "\n",
    "                # Check if this is the closest platoon within the coupling threshold\n",
    "                if distance < 300 and distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_platoon = front_platoon\n",
    "\n",
    "        # If a closest platoon was found, perform the coupling\n",
    "        if closest_platoon:\n",
    "            # Adjust leadership after coupling\n",
    "            rear_platoon.platoon_members[-1].is_leader = False\n",
    "\n",
    "            # Merge the rear platoon behind the closest front platoon\n",
    "            rear_platoon.platoon_members.extend(closest_platoon.platoon_members)\n",
    "            rear_platoon.platoon_members[-1].is_leader = True\n",
    "            # Set target speed for coupling\n",
    "            rear_platoon.platoon_members[-1].target_speed = 0.5\n",
    "            self.platoons.remove(closest_platoon)\n",
    "            del self.dones[closest_platoon]\n",
    "\n",
    "    def step(self, platoon, action, agent_idx):\n",
    "        agent = platoon.platoon_members[agent_idx]\n",
    "\n",
    "        if agent.destination == 1 and agent.direction == 0 and agent.position >= 500:\n",
    "            agent.position = 150\n",
    "            agent.direction = 1   \n",
    "\n",
    "            # Perform the split to get two new platoons\n",
    "            new_exiting_platoon, new_rear_platoon = platoon.split_platoon(agent_idx)\n",
    "\n",
    "            # Append each platoon individually, not as a tuple\n",
    "            if new_exiting_platoon:\n",
    "                self.platoons.append(new_exiting_platoon)\n",
    "                self.dones[new_exiting_platoon] = False\n",
    "            if new_rear_platoon:\n",
    "                self.platoons.append(new_rear_platoon)\n",
    "                self.dones[new_rear_platoon] = False\n",
    "\n",
    "            # Update the state and exit this step early\n",
    "            return [], 0, False, {}\n",
    "\n",
    "        leader = platoon.platoon_members[agent_idx + 1]\n",
    "\n",
    "        agent.update_speed(action)\n",
    "        agent.update_position()\n",
    "\n",
    "        distance_to_leader = (leader.position - agent.position) \n",
    "        done = False\n",
    "\n",
    "        if platoon.platoon_members[-1].direction == 0 and platoon.platoon_members[-1].position >= 950:\n",
    "            self.dones[platoon] = True\n",
    "        elif platoon.platoon_members[-1].direction == 1 and platoon.platoon_members[-1].position >= 600:\n",
    "            self.dones[platoon] = True\n",
    "\n",
    "        state = np.array([distance_to_leader, agent.speed, leader.speed], dtype=np.float32)\n",
    "        agent.velocities.append(agent.speed)\n",
    "        agent.distances.append(distance_to_leader)\n",
    "        return state, 0, done, {}\n",
    "\n",
    "    def update_leader_speed(self, platoon):\n",
    "        any_agent_behind = any(\n",
    "            (platoon.platoon_members[i + 1].position - platoon.platoon_members[i].position > self.target_distance + 10)\n",
    "            for i in range(len(platoon.platoon_members) - 1)\n",
    "        )\n",
    "\n",
    "        if not any_agent_behind:\n",
    "            platoon.platoon_members[-1].target_speed = 1.0 \n",
    "\n",
    "        platoon.platoon_members[-1].update_position()\n",
    "        platoon.platoon_members[-1].update_speed()\n",
    "\n",
    "    def render(self):\n",
    "        if not hasattr(self, 'screen'):\n",
    "            return\n",
    "\n",
    "        self.screen.fill((0, 0, 0))\n",
    "        pygame.draw.line(self.screen, (30, 30, 30), (50, 150), (950, 150), 5)\n",
    "        pygame.draw.line(self.screen, (30, 30, 30), (500, 150), (500, 600), 5)\n",
    "        pygame.draw.circle(self.screen, (255, 0, 0), (950, 150), 10)\n",
    "        pygame.draw.circle(self.screen, (255, 0, 0), (500, 600), 10)\n",
    "        \n",
    "        for platoon in self.platoons:\n",
    "            for agent in platoon.platoon_members:\n",
    "                if agent.direction == 0:\n",
    "                    pygame.draw.rect(self.screen, (0, 255, 0) if not agent.is_leader else (0, 0, 255), pygame.Rect(int(agent.position) - 6, 147, 12, 6))\n",
    "                else:\n",
    "                    pygame.draw.rect(self.screen, (0, 255, 0) if not agent.is_leader else (0, 0, 255), pygame.Rect(497, int(agent.position) - 6, 6, 12))\n",
    "\n",
    "        # speed_text = self.font.render(f\"Leader Speed: {round(self.platoons[0].platoon_members[-1].speed, 3)}\", True, (255, 255, 255))\n",
    "        # self.screen.blit(speed_text, (10, 10))\n",
    "        y_offset = 10  # Starting position for text display\n",
    "        for i, platoon in enumerate(self.platoons):\n",
    "            leader_speed = platoon.platoon_members[-1].speed  # Assuming last member is the leader\n",
    "            text = f\"Platoon {i+1} - Leader Speed: {round(leader_speed, 3)}\"\n",
    "            speed_text = self.font.render(text, True, (255, 255, 255))\n",
    "            self.screen.blit(speed_text, (10, y_offset))\n",
    "            y_offset += 20\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)\n",
    "\n",
    "    def close(self):\n",
    "        if self.is_pygame_initialized:\n",
    "            print(\"Closing Pygame...\")\n",
    "            pygame.quit()\n",
    "            self.is_pygame_initialized = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "rsEO-pezVs0a"
   },
   "outputs": [],
   "source": [
    "# Neural network for Q-learning (DQN)\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "zuEUWIWGq4mv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Pygame...\n",
      "Closing Pygame...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize the environment with visualization\n",
    "env = FollowLeaderEnv(num_agents=6, visualize=True)  # Assuming you want 5 agents for the example\n",
    "\n",
    "# Get the state and action dimensions from the environment\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "# Initialize a new DQN network for testing\n",
    "dqn_test = DQN(state_dim, action_dim)\n",
    "\n",
    "# Load the trained model's weights\n",
    "dqn_test.load_state_dict(torch.load(\"policy_net_weights_final5.pth\"))\n",
    "\n",
    "# Set the model to evaluation mode \n",
    "dqn_test.eval()\n",
    "\n",
    "# Loop to run the episode\n",
    "done = False\n",
    "while not done:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "\n",
    "    time.sleep(0.05)\n",
    "\n",
    "    # Iterate through each platoon, and use a while loop to handle dynamic changes in platoons\n",
    "    platoon_index = 0\n",
    "    while platoon_index < len(env.platoons):\n",
    "        platoon = env.platoons[platoon_index]\n",
    "        \n",
    "        # Iterate through agents in the platoon\n",
    "        agent_index = 0\n",
    "        while agent_index < len(platoon.platoon_members):\n",
    "            agent = platoon.platoon_members[agent_index]\n",
    "            \n",
    "            if agent.is_leader or agent_index == len(platoon.platoon_members) - 1:\n",
    "                agent_index += 1  # Move to the next agent if current agent is the leader or last\n",
    "                continue\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                next_agent = platoon.platoon_members[agent_index + 1]\n",
    "                distance_to_leader = (next_agent.position - agent.position)\n",
    "                \n",
    "                # Decide action based on the distance to the next agent in the platoon\n",
    "                if distance_to_leader > 100:\n",
    "                    action = 2\n",
    "                else:\n",
    "                    action = torch.argmax(dqn_test(torch.FloatTensor([distance_to_leader, agent.speed, next_agent.speed]))).item()\n",
    "\n",
    "            # Take a step in the environment\n",
    "            _, _, _, _ = env.step(platoon, action, agent_index)\n",
    "\n",
    "            if any(env.dones.values()):\n",
    "                done = True\n",
    "                break\n",
    "            \n",
    "            agent_index += 1\n",
    "\n",
    "        # After iterating over agents, update the leaderâ€™s speed and check for coupling\n",
    "        env.update_leader_speed(platoon)\n",
    "        env.check_distance_and_request_coupling(platoon)\n",
    "        \n",
    "        # Re-check platoon list length if a split or merge occurred\n",
    "        if platoon_index < len(env.platoons):\n",
    "            platoon_index += 1\n",
    "\n",
    "    env.render()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FollowLeaderEnv' object has no attribute 'leader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m plot_agent_data(env)\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mplot_agent_data\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Find the minimum length of velocities/distances across all valid agents\u001b[39;00m\n\u001b[0;32m     12\u001b[0m min_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mvelocities) \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m valid_agents)\n\u001b[1;32m---> 13\u001b[0m min_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(min_timesteps, \u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39mleader\u001b[38;5;241m.\u001b[39mvelocities))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Plot velocities for each agent\u001b[39;00m\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FollowLeaderEnv' object has no attribute 'leader'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_agent_data(env):\n",
    "    # Ensure no empty velocity or distance lists for agents\n",
    "    valid_agents = [agent for agent in env.agents if agent.velocities and agent.distances]\n",
    "\n",
    "    if not valid_agents:\n",
    "        print(\"No valid agent data to plot.\")\n",
    "        return\n",
    "\n",
    "    # Find the minimum length of velocities/distances across all valid agents\n",
    "    min_timesteps = min(len(agent.velocities) for agent in valid_agents)\n",
    "    min_timesteps = min(min_timesteps, len(env.leader.velocities))\n",
    "\n",
    "    # Plot velocities for each agent\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot velocities in one plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(min_timesteps), env.leader.velocities[:min_timesteps], label='Leader')\n",
    "    for i, agent in enumerate(valid_agents):\n",
    "        plt.plot(range(min_timesteps), agent.velocities[:min_timesteps], label=f'Agent {i+1}')\n",
    "    plt.title('Velocities over Time')\n",
    "    plt.xlabel('Timesteps')\n",
    "    plt.ylabel('Velocity')\n",
    "    plt.legend()\n",
    "\n",
    "    # Find the minimum length of distances for all valid agents\n",
    "    min_timesteps_dist = min(len(agent.distances) for agent in valid_agents)\n",
    "\n",
    "    # Plot distances (positions) in one plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, agent in enumerate(valid_agents):\n",
    "        plt.plot(range(min_timesteps_dist), agent.distances[:min_timesteps_dist], label=f'Agent {i}')\n",
    "    plt.title('Distances over Time')\n",
    "    plt.xlabel('Timesteps')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_agent_data(env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future research: decision of the leader to allow couple or not.\n",
    "Sort trains by leaving order.\n",
    "not slow down if non trains behind will go to other direction, knowledge of other trains."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
